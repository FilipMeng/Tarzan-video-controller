{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\filip\\.conda\\envs\\soft-ve\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, color=False):\n",
    "    if color:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_range(image):\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_vector(image):\n",
    "    return image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_ann(path, output_size):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    i=0\n",
    "    \n",
    "    for dir in os.listdir(path):\n",
    "        for img in os.listdir(path+\"/\"+dir):\n",
    "            \n",
    "            label = np.zeros(output_size)\n",
    "            label[i] = 1\n",
    "            outputs.append(label)\n",
    "            \n",
    "            readedImg = cv2.imread(path+\"/\"+dir+\"/\"+img, cv2.IMREAD_GRAYSCALE)\n",
    "            scale = scale_to_range(readedImg) #zbog brzeg treniranja\n",
    "            inputs.append(matrix_to_vector(scale))#pripremi za ulaz\n",
    "            \n",
    "        i+=1\n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_predict(path):\n",
    "    readedImg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    scale = scale_to_range(readedImg)\n",
    "    return matrix_to_vector(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_size 7\n",
    "def create_ann(output_size):\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(128, input_dim=40000, activation='sigmoid'))\n",
    "    ann.add(Dense(output_size, activation='sigmoid'))\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ann(ann, x_train, y_train, epochs):\n",
    "    x_train = np.array(x_train, np.float32) # dati ulaz\n",
    "    y_train = np.array(y_train, np.float32) # zeljeni izlazi na date ulaze\n",
    "    \n",
    "    print(\"\\nTraining started...\")\n",
    "    sgd = SGD(lr=0.01, momentum=0.9)\n",
    "    ann.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "    ann.summary()\n",
    "    ann.fit(x_train, y_train, epochs=epochs, batch_size=10, verbose=1, shuffle=True)\n",
    "    print(\"\\nTraining completed...\")\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ann(ann, x_validate, y_validate):\n",
    "    x_validate = np.array(x_validate, np.float32) \n",
    "    y_validate = np.array(y_validate, np.float32)\n",
    "    \n",
    "    print(\"\\nValidating started...\")\n",
    "    loss, acc=ann.evaluate(x_validate, y_validate, batch_size=5, verbose=1)\n",
    "    print(\"loss: \"+str(loss),\"acc: \"+str(acc))\n",
    "    print(\"\\nValidating completed...\")\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(output):\n",
    "    return max(enumerate(output), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"prepare_data/train\"\n",
    "valid_path = \"prepare_data/valid\" \n",
    "test_path = \"prepare_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\"down\",\"left\",\"no\",\"right\",\"up\",\"up-left\",\"up-right\"]\n",
    "inputs, outputs = prepare_for_ann(train_path, len(alphabet))\n",
    "inputs_valid, outputs_valid = prepare_for_ann(valid_path, len(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               5120128   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,121,031\n",
      "Trainable params: 5,121,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0602 - accuracy: 0.8235\n",
      "Epoch 2/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0244 - accuracy: 0.9663\n",
      "Epoch 3/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0170 - accuracy: 0.9770\n",
      "Epoch 4/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0134 - accuracy: 0.9816\n",
      "Epoch 5/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0111 - accuracy: 0.9857\n",
      "Epoch 6/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0095 - accuracy: 0.9857\n",
      "Epoch 7/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0082 - accuracy: 0.9888\n",
      "Epoch 8/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0073 - accuracy: 0.9908\n",
      "Epoch 9/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0066 - accuracy: 0.9918\n",
      "Epoch 10/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0060 - accuracy: 0.9923\n",
      "Epoch 11/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0055 - accuracy: 0.9918\n",
      "Epoch 12/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0050 - accuracy: 0.9939\n",
      "Epoch 13/20\n",
      "1960/1960 [==============================] - 7s 4ms/step - loss: 0.0047 - accuracy: 0.9944\n",
      "Epoch 14/20\n",
      "1960/1960 [==============================] - 7s 4ms/step - loss: 0.0043 - accuracy: 0.9949\n",
      "Epoch 15/20\n",
      "1960/1960 [==============================] - 7s 4ms/step - loss: 0.0040 - accuracy: 0.9949\n",
      "Epoch 16/20\n",
      "1960/1960 [==============================] - 6s 3ms/step - loss: 0.0038 - accuracy: 0.9954\n",
      "Epoch 17/20\n",
      "1960/1960 [==============================] - 6s 3ms/step - loss: 0.0035 - accuracy: 0.9969\n",
      "Epoch 18/20\n",
      "1960/1960 [==============================] - 6s 3ms/step - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 19/20\n",
      "1960/1960 [==============================] - 7s 3ms/step - loss: 0.0032 - accuracy: 0.9980\n",
      "Epoch 20/20\n",
      "1960/1960 [==============================] - 6s 3ms/step - loss: 0.0030 - accuracy: 0.9980\n",
      "\n",
      "Training completed...\n"
     ]
    }
   ],
   "source": [
    "ann = create_ann(len(alphabet))\n",
    "ann = train_ann(ann, inputs, outputs, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating started...\n",
      "245/245 [==============================] - 0s 707us/step\n",
      "loss: 0.004586267162694083 acc: 0.9877551198005676\n",
      "\n",
      "Validating completed...\n"
     ]
    }
   ],
   "source": [
    "loss, acc = validate_ann(ann, inputs_valid, outputs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.save('prepare_data/0.9980ac.h5') #OVO MENJAJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepered_img1 = prepare_for_predict(\"prepare_data/test/down/down_316.pgm\")\n",
    "prepered_img2 = prepare_for_predict(\"prepare_data/test/down/down_327.pgm\")\n",
    "prepered_img3 = prepare_for_predict(\"prepare_data/test/down/down_350.pgm\")\n",
    "real_inp  = []\n",
    "real_inp.append(prepered_img1)\n",
    "real_inp.append(prepered_img2)\n",
    "real_inp.append(prepered_img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ann.predict(np.array(real_inp, np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "down\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    win = winner(r)\n",
    "    print(alphabet[win])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
